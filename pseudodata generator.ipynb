{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Make function to make list of random values.\n",
    "* Cross-product values to make dataframe.\n",
    "* Make table values equivalent of x-values.\n",
    "* Have observation and feature values be y-values.\n",
    "* Specify \"messiness\" for data: null values, missing values, outliers\n",
    "\n",
    "* Make a function to visualize results for spot-checking.\n",
    "\n",
    "Make into class\n",
    "* Add data arrays with add_dimension(len, distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#DEBUGGING\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pseudodata:\n",
    "    \"\"\"\n",
    "    Anticipated workflow\n",
    "    1. Create Pseudodata instance.\n",
    "    2. Add two or more distribution arrays.\n",
    "    3. Generate an output pseudodata DataFrame from the distribution arrays.\n",
    "    4. Add an additional array to the dataset. Give option to update the pseudodata DataFrame automatically or manually (with method).\n",
    "    5. Output the pseudodata DataFrame as Pandas object. OPTIONAL OTHER FORMATS?\n",
    "    6. VISUALIZE THE DATAFRAME?\n",
    "    \n",
    "    Development plan\n",
    "    * Make function_string formatter, so that most input string are modified to be evaluatable as callable functions. (Including size arguments for Numpy distribution methods.)\n",
    "    * Make data generation lazy. Adding distributions should only automatically update the data_profile dictionary; the user can change the option or run generate_dataframe or update_dataframe.\n",
    "    * Allow add_array to use non-Numpy distribution functions.\n",
    "    * Allow allow arrays to be regenerated so a new sample can be drawn from the same distribution.\n",
    "    \n",
    "    Ideas to consider\n",
    "    * \"dataframe\" objects are tuples of the DataFrames and snapshots of data_profiles used for generation. I.e., dataframe = (data_profile, pandas.DataFrame).\n",
    "    * Distribution arrays should be stored. Advantage: able to reference values later and reconstruct DataFrame objects. Disadvantage: memory storage.\n",
    "    * DataFrames are best visualized with pairplots, especially for multiple (2+) dimensions.\n",
    "    * Users should have the option to export DataFrames as CSVs and SQL files.\n",
    "    \"\"\"\n",
    "    \n",
    "    data_profile = dict()\n",
    "    features_data = dict()\n",
    "    dataframe = pandas.DataFrame()\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        self._check_setup()\n",
    "        self.data_profile = dict()\n",
    "        self.features_data = dict()\n",
    "        self.dataframe = pandas.DataFrame()\n",
    "            \n",
    "    \n",
    "    def __call__(self):\n",
    "        # WHAT DOES THIS DO?\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def _check_setup(self):\n",
    "        try:\n",
    "            modules\n",
    "        except:\n",
    "            from sys import modules\n",
    "        \n",
    "        for module in ['pandas', 'numpy']:\n",
    "            if module not in modules:\n",
    "                print(\"{} not imported\".format(module))\n",
    "\n",
    "\n",
    "    def show_data_profile(self):\n",
    "        \"\"\"Displays a description of the arrays in the Pseudodata instance as a DataFrame object.\"\"\"\n",
    "        return pandas.DataFrame(self.data_profile).T\n",
    "\n",
    "    def list_available_distributions(self, detailed_list=False):\n",
    "        \"\"\"Returns the univariate distributions available in numpy.random.\"\"\"\n",
    "        rand_docstring = numpy.random.__doc__\n",
    "        prefiltered_doc_string = rand_docstring.split('variate distributions')[1].split('\\n')\n",
    "        dist_filter = filter(lambda x: 'distribution' in x, prefiltered_doc_string)\n",
    "        dist_list = [element.split(' ')[0] for element in dist_filter]\n",
    "        \n",
    "        if detailed_list == False:\n",
    "            return dist_list\n",
    "        else:\n",
    "            detailed_dist_list = list()\n",
    "            for distribution in dist_list:\n",
    "                dist_docstring = eval(\"numpy.random.{}.__doc__\".format(distribution))\n",
    "                details = dist_docstring.split('\\n')[1].strip()\n",
    "                detailed_dist_list.append(details)\n",
    "            return detailed_dist_list    \n",
    "\n",
    "    def _is_evaluatable(self, input_string):\n",
    "        \"\"\"Tests if a string refers to an object that can be evaluated.\"\"\"\n",
    "        try:\n",
    "            eval(input_string)\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    def _is_callable(self, input_string):\n",
    "        \"\"\"Tests if a string refers to a callable object.\"\"\"\n",
    "        try:\n",
    "            return callable(eval(input_string))\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    def _add_size(self, input_string, size):\n",
    "        \"\"\"Adds a size argument to \"\"\"\n",
    "        if 'size' in input_string or size == None:\n",
    "            return input_string\n",
    "        elif '()' in input_string:\n",
    "            return input_string.replace('()', '(size={0})'.format(size))\n",
    "        else:\n",
    "            return input_string.replace(')', ', size={0})'.format(size))\n",
    "\n",
    "    def _format_function_string(self, input_string, size_argument=None):\n",
    "        \"\"\"IN PROGRESS \n",
    "        Makes any necessary changes to the distribution function string so that it can make feature data.\"\"\"\n",
    "        if input_string.split('(')[0] in self.list_available_distributions():\n",
    "            input_string = 'numpy.random.{0}'.format(input_string)\n",
    "        if self._is_evaluatable(input_string) == False:\n",
    "            return input_string\n",
    "        callable_string_cases = {True: input_string + \"()\", \n",
    "                                 False: input_string}\n",
    "        callable_string = callable_string_cases.get(self._is_callable(input_string))\n",
    "        test_string = self._add_size(callable_string, size_argument)\n",
    "        try:\n",
    "            eval(test_string)\n",
    "            return test_string\n",
    "        except:\n",
    "            return callable_string\n",
    "    \n",
    "    def _make_data_array(self, distribution='normal', list_len=10):\n",
    "        \"\"\"Creates a 1-D Numpy array of specified length using the specified univariate distribution function from Numpy.random.\"\"\"\n",
    "        function_string = self._format_function_string(input_string=distribution, size_argument=list_len)\n",
    "        print(function_string)  # DEBUGGING\n",
    "        test_value = eval(function_string)\n",
    "        if isinstance(test_value, type(numpy.array([]))) or isinstance(test_value, list):\n",
    "            result = eval(function_string)\n",
    "        else:\n",
    "            result = [eval(function_string) for _ in range(list_len)]\n",
    "        return numpy.array(result)\n",
    "\n",
    "    def _make_Nd_dataframe(self, arrays):\n",
    "        \"\"\"Handles N-dimensions.\"\"\"\n",
    "        grid = numpy.meshgrid(*arrays)\n",
    "        reshaped_grid = numpy.dstack(grid).reshape(-1, len(arrays))\n",
    "        dataframe = pandas.DataFrame(reshaped_grid)\n",
    "        products = dataframe.product(axis=1)\n",
    "        dataframe.index = products\n",
    "        return dataframe.sort_index()\n",
    "    \n",
    "    def add_feature(self, distribution='normal', size=10, remake_dataframe=False):\n",
    "        \"\"\"Adds a data array to the Pseudodata instance. \n",
    "        \n",
    "        Refer to Pseudodata.list_available_distributions() to see available distibution options. Examples:\n",
    "        a.add_array()\n",
    "        a.add_array(distribution='poisson')\n",
    "        a.add_array(distribution='binomial(10, .5)')\n",
    "        \"\"\"\n",
    "        data_array = self._make_data_array(distribution=distribution, list_len=size)\n",
    "        feature_id = max(self.data_profile.keys(), default=-1) + 1\n",
    "        self.data_profile[feature_id] = {'size': data_array.shape[0], 'distribution': distribution}\n",
    "        self.features_data[feature_id] = data_array\n",
    "        \n",
    "        if remake_dataframe == True:\n",
    "            self.make_Nd_dataframe(self.features_data.values())\n",
    "\n",
    "    def remove_feature(self, feature_index, remake_dataframe=False):\n",
    "        \"\"\"Removes a feature by data profile index.\"\"\"\n",
    "        self.data_profile.pop(feature_index, None)\n",
    "        self.features_data.pop(feature_index, None)\n",
    "        if remake_dataframe == True:\n",
    "            self._make_Nd_dataframe(self.features_data.values())\n",
    "            \n",
    "    def generate_dataframe(self, feature_index=None):\n",
    "        \"\"\"Generates a new dataframe from all features in the Pseudodata instance or from a specified list of data profile indicies.\"\"\"\n",
    "        if feature_index != None:\n",
    "            for item in feature_index:\n",
    "                if item not in self.data_profile:\n",
    "                    raise KeyError(\"{0} is not in the data profile.\".format(item))\n",
    "            filtered_features_data = [self.features_data.get(key) for key in feature_index]\n",
    "            feature_array = numpy.array(filtered_features_data)\n",
    "            return self._make_Nd_dataframe(feature_array)\n",
    "        else:\n",
    "            return self._make_Nd_dataframe(self.features_data.values())\n",
    "\n",
    "    def regenerate_feature(self, feature_index):\n",
    "        \"\"\"Resamples a specific feature according to its data profile index.\"\"\"\n",
    "        feature_details = self.data_profile.get(feature_index)\n",
    "        data_array = self._make_data_array(feature_details['size'], feature_details['distribution'])\n",
    "        self.features_data[feature_index] = data_array\n",
    "\n",
    "    def display_data(self, input_data):\n",
    "        \"\"\"IN PROGRESS\"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy.random.normal(size=10)\n",
      "numpy.random.normal(size=50)\n",
      "numpy.random.normal(size=30)\n",
      "{0: {'distribution': 'normal', 'size': 10},\n",
      " 1: {'distribution': 'normal', 'size': 50},\n",
      " 2: {'distribution': 'normal', 'size': 30}}\n"
     ]
    }
   ],
   "source": [
    "a = Pseudodata()\n",
    "a.add_feature()\n",
    "a.add_feature(size=50)\n",
    "a.add_feature(size=30)\n",
    "\n",
    "pprint(a.data_profile)\n",
    "b = a.generate_dataframe()\n",
    "print(\"DATAFRAME GENERATION ISSUE: \\n{0:.2f}% of the DataFrame rows are duplicates.\".format(100 * b.duplicated().sum() / b.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting function strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def test(function=eval):\n",
    "#     def wrapper(process):\n",
    "#         try:\n",
    "#             function(process)\n",
    "#             return True\n",
    "#         except:\n",
    "#             return False\n",
    "#     return wrapper\n",
    "\n",
    "# @test\n",
    "def my_function(string):\n",
    "    return string\n",
    "\n",
    "\n",
    "def test(function_string, mode='eval'):\n",
    "    test_function = (eval, callable)[mode=='callable']\n",
    "    return test_function(eval(function_string))\n",
    "\n",
    "print(test(\"my_function\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function result: False\n",
      "True\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "eval() arg 1 must be a string, bytes or code object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-204918848707>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miscallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: eval() arg 1 must be a string, bytes or code object"
     ]
    }
   ],
   "source": [
    "# def test(function):\n",
    "#     def wrapper(*args):\n",
    "#         function(*args)\n",
    "#     return wrapper\n",
    "\n",
    "def test(function):\n",
    "    def wrapper(*args):\n",
    "        try:\n",
    "            print(\"Function result:\", function(*args))\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "    return wrapper\n",
    "\n",
    "@test\n",
    "def iscallable(string):\n",
    "    \"\"\"Tests if the string represents a callable function.\"\"\"\n",
    "    return callable(eval(string))\n",
    "\n",
    "@test\n",
    "def iseval(string):\n",
    "    \"\"\"Tests if the string represents an evaluatable object.\"\"\"\n",
    "    return eval(string)\n",
    "\n",
    "# print(iseval(1))\n",
    "# print(iseval(\"1\"))\n",
    "# print(eval(\"1\"))\n",
    "\n",
    "print(iscallable(\"1\"))\n",
    "print(callable(eval(1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n"
     ]
    }
   ],
   "source": [
    "def check(func):  # takes function as argument\n",
    "    def inside(a, b):\n",
    "        if b == 0:\n",
    "            return \"Cannot divide by 0.\"\n",
    "        else:\n",
    "            return func(a, b)  # run divide function\n",
    "    return inside  # execute the inside function\n",
    "    \n",
    "@check\n",
    "def divide(a, b):\n",
    "    return a / b\n",
    "\n",
    "\n",
    "# Implementations\n",
    "# divide = check(divide)  # redefine divide function call\n",
    "# Or decorator\n",
    "\n",
    "print(divide(10,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Simplify by making a test decorator\n",
    "# # DOESN'T WORK\n",
    "# def test(process):\n",
    "#     def wrapper(*args):\n",
    "#         try:\n",
    "#             process(*args)\n",
    "#             return True\n",
    "#         except:\n",
    "#             return False\n",
    "#     return wrapper\n",
    "\n",
    "# @test\n",
    "# def is_callable(function):\n",
    "#     callable(function)\n",
    "\n",
    "# is_callable('my_functions')\n",
    "\n",
    "\n",
    "# # ====== \n",
    "\n",
    "\n",
    "def _is_evaluatable(input_string):\n",
    "    \"\"\"Tests if a string refers to an object that can be evaluated.\"\"\"\n",
    "    try:\n",
    "        eval(input_string)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "def _is_callable(input_string):\n",
    "    \"\"\"Tests if a string refers to a callable object.\"\"\"\n",
    "    try:\n",
    "        return callable(eval(input_string))\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def _add_size(input_string, size):\n",
    "    \"\"\"Adds a size argument to \"\"\"\n",
    "    if 'size' in input_string or size == None:\n",
    "        return input_string\n",
    "    elif '()' in input_string:\n",
    "        return input_string.replace('()', '(size={0})'.format(size))\n",
    "    else:\n",
    "        return input_string.replace(')', ', size={0})'.format(size))\n",
    "    \n",
    "def _format_function_string(input_string, size_argument=None):\n",
    "    if _is_evaluatable(input_string) == False:\n",
    "        return input_string\n",
    "    callable_string_cases = {True: input_string + \"()\",\n",
    "                             False: input_string}\n",
    "    callable_string = callable_string_cases.get(_is_callable(input_string))\n",
    "    test_string = _add_size(callable_string, size_argument)\n",
    "    try:\n",
    "        eval(test_string)\n",
    "        return test_string\n",
    "    except:\n",
    "        return callable_string\n",
    "    \n",
    "    \n",
    "size=100\n",
    "a = '0.5'  # Returns '0.5'\n",
    "b = 'non-function'  # Returns error\n",
    "c = 'normal'  # Returns np.random.normal(size=100)\n",
    "d = 'numpy.random.normal'  # Returns 'np.random.normal(size=100)'\n",
    "e = 'numpy.random.normal()'  # Returns 'np.random.normal(size=100)'\n",
    "f = 'numpy.random.binomial(10, .5)'  # 'np.random.binomial(10, .5, size=100)'\n",
    "g = 'numpy.random.binomial(10, .5, size=10)' # Returns 'np.random.binomial(10, .5, size=10)'\n",
    "\n",
    "def my_function():\n",
    "    return \"HI!\"\n",
    "\n",
    "for case in [a, b, c, d, e, f, g]:\n",
    "    print(case, '-->', _format_function_string(case, size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making N-dimensional DataFrames"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# PREVIOUS WORKING VERSION\n",
    "def invert_dataframe(input_dataframe=None):\n",
    "    \"\"\"Inverts a DataFrame, where the values become the index and the column and row indicies become values.\"\"\"\n",
    "    if input_dataframe is None:\n",
    "        return None\n",
    "    \n",
    "    reshaped_dataframe = input_dataframe.stack().reset_index().set_index(0)\n",
    "    \n",
    "    feature_count = reshaped_dataframe.shape[1]\n",
    "    feature_names = list(range(feature_count))\n",
    "    reshaped_dataframe.columns = feature_names\n",
    "\n",
    "    return reshaped_dataframe.sort_index()\n",
    "\n",
    "def make_dataframe(array_1=None, array_2=None):\n",
    "    \"\"\"Create a DataFrame from the elementwise product of two iterables.\"\"\"\n",
    "\n",
    "    result_dataframe = pd.DataFrame(index=array_1, columns=array_2)\n",
    "    \n",
    "    # Iterative operations are generally faster if row length is greater than the number of columns.\n",
    "    if result_dataframe.shape[0] < result_dataframe.shape[1]:\n",
    "        result_dataframe = result_dataframe.T\n",
    "    \n",
    "    result_dataframe = result_dataframe.apply(lambda series: series.index) * result_dataframe.columns\n",
    "   \n",
    "    return invert_dataframe(result_dataframe)\n",
    "\n",
    "# ==============================\n",
    "\n",
    "# TEST VERSION\n",
    "def make_Nd_dataframe(arrays):\n",
    "    \"\"\"Handles N-dimensions.\"\"\"\n",
    "    grid = np.meshgrid(*arrays)\n",
    "    reshaped_grid = np.dstack(grid).reshape(-1, len(arrays))\n",
    "    dataframe = pd.DataFrame(reshaped_grid)\n",
    "    products = dataframe.product(axis=1)\n",
    "    dataframe.index = products\n",
    "    return dataframe.sort_index()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "a = [[np.random.normal() for _ in range(1000)] for _ in range(2)]  # List of 2 1000x1 arrays\n",
    "b = [[np.random.normal() for _ in range(100)], [np.random.normal() for _ in range(1000)]]  # List of 1 100x1 and 1 1000x1 arrays\n",
    "c = [[np.random.normal() for _ in range(100)] for _ in range(3)]  # List of 3 100x1 arrays\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "difference_df = make_dataframe(*a) - make_Nd_dataframe(a)\n",
    "(difference_df != 0).any()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%timeit make_Nd_dataframe(a)\n",
    "%timeit make_dataframe(*a)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%timeit make_Nd_dataframe(b)\n",
    "%timeit make_dataframe(*b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deprecated working methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def make_dataframe(array_1=None, array_2=None):\n",
    "#     \"\"\"Create a DataFrame from the elementwise product of two iterables.\"\"\"\n",
    "    \n",
    "#     if array_1 is None or array_2 is None:\n",
    "#         return None\n",
    "    \n",
    "#     if array_1.shape[0] < array_2.shape[0]:\n",
    "#         index_array = array_1\n",
    "#         column_array = array_2\n",
    "#     else:\n",
    "#         index_array = array_2\n",
    "#         column_array = array_1\n",
    "\n",
    "#     result_dataframe = pd.DataFrame(index=index_array, columns=column_array)\n",
    "#     for row in result_dataframe.iterrows():\n",
    "#         result_dataframe.loc[row[0]] = row[0] * result_dataframe.columns\n",
    "#     return result_dataframe\n",
    "\n",
    "\n",
    "# # PHASED OUT 4-July-2018\n",
    "# # REPLACED BY make_Nd_dataframe\n",
    "# def _make_dataframe(self, array_1=None, array_2=None):\n",
    "#     \"\"\"Create a DataFrame from the elementwise product of two iterables.\"\"\"\n",
    "\n",
    "#     result_dataframe = pd.DataFrame(index=array_1, columns=array_2)\n",
    "\n",
    "#     # Iterative operations are generally faster if row length is greater than the number of columns.\n",
    "#     if result_dataframe.shape[0] < result_dataframe.shape[1]:\n",
    "#         result_dataframe = result_dataframe.T\n",
    "\n",
    "#     result_dataframe = result_dataframe.apply(lambda series: series.index) * result_dataframe.columns\n",
    "\n",
    "#     return result_dataframe\n",
    "\n",
    "# # PHASED OUT 4-July-2018\n",
    "# # PAIRED WITH _make_dataframe\n",
    "# # MADE OBSOLETE BY make_Nd_dataframe\n",
    "# def _invert_dataframe(self, input_dataframe=None):\n",
    "#     \"\"\"Inverts a DataFrame, where the values become the index and the column and row indicies become values.\"\"\"\n",
    "#     if input_dataframe is None:\n",
    "#         return None\n",
    "#     reshaped_dataframe = input_dataframe.stack().reset_index().set_index(0)\n",
    "#     feature_count = reshaped_dataframe.shape[1]\n",
    "#     feature_names = list(range(feature_count))\n",
    "#     reshaped_dataframe.columns = feature_names\n",
    "#     return reshaped_dataframe.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ALLOW USER TO DEFINE CALLABLE AS DISTRIBUTION\n",
    "def EXPERIMENTAL_make_data_list_USER_FUNC(list_len=10, distribution='normal'):\n",
    "    \"\"\"Creates a 1-D Numpy array of specified length using the specified univariate distribution function from Numpy.random \n",
    "    OR A USER-DEFINED FUNCTION.\"\"\"\n",
    "    if distribution in list_available_distributions():\n",
    "        rand_method_call = 'numpy.random.{}'.format(distribution)\n",
    "    elif callable(eval(distribution)):\n",
    "        rand_method_call = distribution\n",
    "    else:\n",
    "        print(\"{} is not callable.\".format(distribution))\n",
    "        return None\n",
    "    \n",
    "    result_list = [eval(\"{}()\".format(rand_method_call)) for _ in range(list_len)]\n",
    "    result_array = numpy.array(result_list)\n",
    "    return result_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration of functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = Pseudodata()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.list_available_distributions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.add_feature(100)\n",
    "a.add_feature(100, distribution='poisson')\n",
    "a.add_feature(100, distribution='normal(loc=5)')\n",
    "a.add_feature(100, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.show_data_profile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.remove_feature(1)\n",
    "a.add_feature(10, distribution='poisson')\n",
    "a.show_data_profile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.remove_feature(3)\n",
    "a.show_data_profile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df = a.generate_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df.hist()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# seaborn.pairplot(test_df)\n",
    "# plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print((test_df[0] == test_df[1]).sum() / test_df.shape[0])\n",
    "\n",
    "print((test_df[1] == test_df[2]).sum() / test_df.shape[0])\n",
    "\n",
    "# WHAT'S GOING ON HERE?\n",
    "# test_df.loc[test_df[0] == test_df[1], :].merge(test_df.loc[test_df[1] == test_df[2], :], how='inner', left_index=True, right_index=True)\n",
    "test_df[0].value_counts()\n",
    "test_df.duplicated().sum() / test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a._make_data_array().nbytes  # PRINTS BYTESIZE OF ARRAYS. USE FOR STORAGE TESTING (IE, PRINT TOTAL SIZE FOR STORED V. NOT STORED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method chaining\n",
    "\n",
    "Example\n",
    "\n",
    ">`Pseudodata().add_array(100).add_array('binomial(10,0.5)').generate_dataframe()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Test:\n",
    "    value = list()\n",
    "    def __init__(self):\n",
    "        self.value = [1]\n",
    "    \n",
    "    def add_one(self, inplace=False):\n",
    "        self.value.append(self.value[-1] + 1)\n",
    "        return self\n",
    "    \n",
    "    def print_value(self):\n",
    "        print(self.value)\n",
    "        \n",
    "b = Test()\n",
    "b.add_one().add_one().add_one().add_one()\n",
    "print(\"b.print_value():\", b.print_value())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
